{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T16:26:31.229451Z",
     "start_time": "2018-12-27T16:26:31.008474Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agents package successfully initialized.\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "\n",
    "import time \n",
    "from IPython.display import Video\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Importing custom modules\n",
    "from engine_DP import CoinGame\n",
    "from agents import (\n",
    "    ManhattanAgent, ManhattanAgent_Passive, ManhattanAgent_Aggressive, ManhattanAgent_Ultra_Aggressive,\n",
    "    IndQLearningAgentSoftmax, LevelKQAgent, LevelKQAgentSoftmax,\n",
    "    LevelKDPAgent_Stationary, LevelKDPAgent_NonStationary, LevelKDPAgent_Dynamic, DPAgent_PerfectModel)\n",
    "\n",
    "from utils.exploration_schedule_utils import linear_epsilon_decay\n",
    "from utils.plot_utils import plot, animate_trajectory_from_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup experiment 1\n",
    "\n",
    "# Number of experiments\n",
    "N_EXP = 3\n",
    "\n",
    "# Size of single dimension of the square grid\n",
    "grid_size = 7\n",
    "\n",
    "# Initialize environment \n",
    "env = CoinGame(max_steps=20000, grid_size=grid_size, push_distance=2)\n",
    "\n",
    "# Number of states \n",
    "n_states = env.n_states\n",
    "\n",
    "# Number of episodes \n",
    "n_iter = 10000\n",
    "\n",
    "# Constant gamma \n",
    "gamma = 0.95\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Moving average window size for plotting \n",
    "moving_average_window_size = 100\n",
    "\n",
    "r0ss = []\n",
    "r1ss = []\n",
    "\n",
    "# Setup parameters for linear decay of exploration parameter\n",
    "epsilon_begin = 1\n",
    "epsilon_end = 0.1\n",
    "\n",
    "\n",
    "# Pre-calculate array of linearly decaying exploration parameter for both agents\n",
    "\n",
    "linear_epsilon_decay_arr = linear_epsilon_decay(epsilon_begin=epsilon_begin, epsilon_end=epsilon_end,n_iter=n_iter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     44\u001b[39m s_new, rewards, done =  env.step((a1,a2))\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Agents update their Q/Value functions\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# * Note: They update their Q/Value functions simultaneously\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mP1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m P2.update(s, (a2, a1), (rewards[\u001b[32m1\u001b[39m], rewards[\u001b[32m0\u001b[39m]), s_new)\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Set the current state to the new state\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/ARAMARL_TMDP_DP/TMDP_DP/agents/q_learning.py:82\u001b[39m, in \u001b[36mIndQLearningAgent.update\u001b[39m\u001b[34m(self, obs, actions, new_obs, rewards)\u001b[39m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mIndQLearningAgent requires a rewards tuple for its update method.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     81\u001b[39m self_action, _ = actions\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m self_reward, _ = rewards\n\u001b[32m     84\u001b[39m \u001b[38;5;28mself\u001b[39m.Q[obs, self_action] = (\u001b[32m1\u001b[39m - \u001b[38;5;28mself\u001b[39m.learning_rate)*\u001b[38;5;28mself\u001b[39m.Q[obs, self_action] + \u001b[38;5;28mself\u001b[39m.learning_rate*(self_reward + \u001b[38;5;28mself\u001b[39m.gamma*np.max(\u001b[38;5;28mself\u001b[39m.Q[new_obs, :]))\n",
      "\u001b[31mTypeError\u001b[39m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "# Run the experiments\n",
    "for n in range(N_EXP):\n",
    "    \n",
    "    ## Initialize agents\n",
    "    #* Note: The agent's here are reinitialized, instead reset can be done by reseting the Q matrix inside the agent.\n",
    "    \n",
    "    P1 = IndQLearningAgentSoftmax(np.array(range(8)), n_states, learning_rate=learning_rate,\n",
    "                           epsilon=epsilon_begin, gamma=gamma, beta = 1)\n",
    "    \n",
    "    P2 = IndQLearningAgentSoftmax(np.array(range(8)), n_states, learning_rate=learning_rate,\n",
    "                           epsilon=epsilon_begin, gamma=gamma, beta = 1)\n",
    "\n",
    "\n",
    "    # P2 = ExpSmoother(env.available_actions_Adv, env.available_actions_Adv, learning_rate=0.7)\n",
    "    # P2 = RandomAgent( env.available_actions, p=0.5)\n",
    "\n",
    "    \n",
    "    # Reset the reward vectors for the experiment\n",
    "    r0s = []\n",
    "    r1s = []\n",
    "    \n",
    "    # Run through episodes\n",
    "    for i in range(n_iter):\n",
    "\n",
    "        # Initialize the end of episode flag\n",
    "        done = False\n",
    "        # Reset the environment after each episode\n",
    "        env.reset()\n",
    "        # Get the initial state\n",
    "        s = env.get_state()\n",
    "        \n",
    "        # Initialize cummulative observed rewards for this episode\n",
    "        episode_rewards_DM = 0\n",
    "        episode_rewards_Adv = 0\n",
    "        \n",
    "        # While the agents have not reached the terminal state\n",
    "        while not done:\n",
    "            # Agents choose actions \n",
    "            # * Note: They choose the actions simultaneously\n",
    "            a1 = P1.act(obs=s)\n",
    "            a2 = P2.act(obs=s)\n",
    "\n",
    "            # Transition to next time step\n",
    "            s_new, rewards, done =  env.step((a1,a2))\n",
    "\n",
    "            # Agents update their Q/Value functions\n",
    "            # * Note: They update their Q/Value functions simultaneously\n",
    "            P1.update(s, (a1, a2), s_new, (rewards[0], rewards[1]))\n",
    "            P2.update(s, (a2, a1), s_new, (rewards[1], rewards[0]))\n",
    "            \n",
    "            # Set the current state to the new state\n",
    "            s = s_new  \n",
    "            \n",
    "            # Add the observed reward to the episode reward of both agents \n",
    "            # * Note: The rewards are observed simultaneously\n",
    "            episode_rewards_DM += rewards[0]\n",
    "            episode_rewards_Adv += rewards[1]\n",
    "            \n",
    "        # After an epoch apply decay to exploration parameter\n",
    "        P1.epsilon = linear_epsilon_decay_arr[i]\n",
    "        # P1.enemy.epsilon = linear_epsilon_decay_arr[i]\n",
    "        # P1.enemy.enemy.epsilon = linear_epsilon_decay_arr[i]\n",
    "        P2.epsilon = linear_epsilon_decay_arr[i]\n",
    "            \n",
    "        # Append the episode rewards to the list of rewards for this experiment\n",
    "        r0s.append(episode_rewards_DM)\n",
    "        # Append the episode rewards to the list of rewards for this experiment\n",
    "        r1s.append(episode_rewards_Adv)\n",
    "        \n",
    "        env.reset()\n",
    "    \n",
    "          \n",
    "\n",
    "    print(n)\n",
    "    r0ss.append(r0s)\n",
    "    r1ss.append(r1s)\n",
    "    \n",
    "plot(r0ss, r1ss, moving_average_window_size=moving_average_window_size, dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c49e6894f3487eb83020eefc8ade57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Experiments:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544a21b0e60a4944a0ebd4b73b1e8c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Initializing value function.:   0%|          | 0/38416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b26cc2e8cb34ecf9228c30e46178a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Initializing value function.:   0%|          | 0/38416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2096cbbfb94c61bf49266e3bc02be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Initializing value function.:   0%|          | 0/38416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13719e8f04e41bb800abe88da92c886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Initializing value function.:   0%|          | 0/38416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6733fb189d144dcb8ca8987ccf5710c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs (Exp 1):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14eec089cf344bc995cc8c70df3c2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Initializing value function.:   0%|          | 0/38416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05897b80ea24e85bcd259ed47222d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Initializing value function.:   0%|          | 0/38416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2a80407c054bea9750f07b4eea348e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Initializing value function.:   0%|          | 0/38416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06206072284b4ed085db927d12a9e2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Initializing value function.:   0%|          | 0/38416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20f1df0825746e6b28b24d4a0989e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs (Exp 2):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 83\u001b[39m\n\u001b[32m     80\u001b[39m Adv_location_old = env.player_1_pos.copy()\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Transition to next time step\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m s_new, rewards, done =  \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Agents update their Q/Value functions\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# * Note: They update their Q/Value functions simultaneously\u001b[39;00m\n\u001b[32m     87\u001b[39m P1.update(s, (a1, a2), s_new, (rewards[\u001b[32m0\u001b[39m], rewards[\u001b[32m1\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/ARAMARL_TMDP_DP/TMDP_DP/engine.py:377\u001b[39m, in \u001b[36mCoinGame.step\u001b[39m\u001b[34m(self, actions)\u001b[39m\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.any(candidate_pos < \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m np.any(candidate_pos >= \u001b[38;5;28mself\u001b[39m.grid_size):\n\u001b[32m    376\u001b[39m         reward_1 += \u001b[38;5;28mself\u001b[39m._OUT_OF_BOUNDS_PENALTY_DELTA\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     new_pos_1 = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;66;03m# Resolve collisions: if agents move to the same spot, they bounce back.\u001b[39;00m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.array_equal(new_pos_0, new_pos_1):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/TMDP_DP/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:2329\u001b[39m, in \u001b[36mclip\u001b[39m\u001b[34m(a, a_min, a_max, out, min, max, **kwargs)\u001b[39m\n\u001b[32m   2325\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mmin\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np._NoValue \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mmax\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np._NoValue:\n\u001b[32m   2326\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPassing `min` or `max` keyword argument when \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2327\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33m`a_min` and `a_max` are provided is forbidden.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclip\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/TMDP_DP/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:57\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/TMDP_DP/lib/python3.13/site-packages/numpy/_core/_methods.py:102\u001b[39m, in \u001b[36m_clip\u001b[39m\u001b[34m(a, min, max, out, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_clip\u001b[39m(a, \u001b[38;5;28mmin\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mmax\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m a.dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33miu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    100\u001b[39m         \u001b[38;5;66;03m# If min/max is a Python integer, deal with out-of-bound values here.\u001b[39;00m\n\u001b[32m    101\u001b[39m         \u001b[38;5;66;03m# (This enforces NEP 50 rules as no value based promotion is done.)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mmin\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mint\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mmin\u001b[39m <= \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43miinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m.min:\n\u001b[32m    103\u001b[39m             \u001b[38;5;28mmin\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    104\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mmax\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mint\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mmax\u001b[39m >= np.iinfo(a.dtype).max:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/TMDP_DP/lib/python3.13/site-packages/numpy/_core/getlimits.py:698\u001b[39m, in \u001b[36miinfo.__init__\u001b[39m\u001b[34m(self, int_type)\u001b[39m\n\u001b[32m    694\u001b[39m _max_vals = {}\n\u001b[32m    696\u001b[39m __class_getitem__ = \u001b[38;5;28mclassmethod\u001b[39m(types.GenericAlias)\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, int_type):\n\u001b[32m    699\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    700\u001b[39m         \u001b[38;5;28mself\u001b[39m.dtype = numeric.dtype(int_type)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "r0ss = []\n",
    "r1ss = []\n",
    "\n",
    "# Total trajectory logs for all experiments\n",
    "trajectory_logs_all_experiments = []\n",
    "\n",
    "# Run the experiments\n",
    "for n in tqdm(range(N_EXP), desc=\"Experiments\"):\n",
    "    \n",
    "    np.random.seed(n)\n",
    "    \n",
    "    ## Initialize agents\n",
    "    # TODO: Add reset method to individual agents and move them to initialization\n",
    "    #* Note: The agent's here are reinitialized, instead reset can be done by reseting the Q matrix inside the agent.\n",
    "    \n",
    "    P1 = LevelKQAgent(k=3, action_space=np.array(range(8)), opponent_action_space=np.array(range(8)),\n",
    "                      n_states=n_states, grid_size=grid_size, learning_rate=learning_rate, epsilon=epsilon_begin, gamma=gamma)\n",
    "    \n",
    "    # P1 = IndQLearningAgentSoftmax(np.array(range(8)), n_states, learning_rate=learning_rate,\n",
    "    #                        epsilon=linear_epsilon_decay_arr[0], gamma=gamma, opponent_action_space=None, beta = 1)\n",
    "\n",
    "    \n",
    "    # P2 = IndQLearningAgentSoftmax(np.array(range(8)), n_states, learning_rate=learning_rate,\n",
    "    #                        epsilon=epsilon_begin, gamma=gamma, opponent_action_space=None, beta = 1)\n",
    "    \n",
    "    # P2 = ManhattanAgent(action_space=np.array(range(8)), coin_location = np.array([env.coin_0_pos, env.player_1_pos]), grid_size = grid_size, player_id = 1)\n",
    "\n",
    "    P2 = LevelKQAgent(k=1, action_space=np.array(range(8)), opponent_action_space=np.array(range(8)),\n",
    "                      n_states=n_states, grid_size=grid_size, learning_rate=learning_rate, epsilon=epsilon_begin, gamma=gamma)\n",
    "    \n",
    "    # Reset the reward vectors for the experiment\n",
    "    r0s = []\n",
    "    r1s = []\n",
    "    \n",
    "    # Trajectory logs for visualization\n",
    "    trajectory_logs_single_experiment = []\n",
    "    \n",
    "    # Run through episodes\n",
    "    for i in tqdm(range(n_iter), desc=f\"Epochs (Exp {n+1})\"):\n",
    "\n",
    "        # Initialize the end of episode flag\n",
    "        done = False\n",
    "        # Reset the environment after each episode\n",
    "        env.reset()\n",
    "        # Get the initial state\n",
    "        s = env.get_state()\n",
    "        # Trajectory log for this episode\n",
    "        trajectory_log_single_epoch = []\n",
    "        \n",
    "        # Log the initial state immediately after env.reset()\n",
    "        trajectory_log_single_epoch.append({\n",
    "            'DM_location_old': [\"None\", \"None\"],\n",
    "            'Adv_location_old': [\"None\", \"None\"],\n",
    "            'DM_location_new': env.player_0_pos.copy(),\n",
    "            'Adv_location_new': env.player_1_pos.copy(),\n",
    "            'coin1': env.coin_0_pos.copy() if env.coin0_available else None,\n",
    "            'coin2': env.coin_1_pos.copy() if env.coin1_available else None, \n",
    "            'action_DM': [\"None\", \"None\"],\n",
    "            'action_Adv': [\"None\", \"None\"],\n",
    "            'reward_DM': None,\n",
    "            'reward_Adv': None,\n",
    "            'state': s, \n",
    "            'experiment': n,\n",
    "            'epoch': i\n",
    "        })\n",
    "\n",
    "        # Initialize cummulative observed rewards for this episode\n",
    "        episode_rewards_DM = 0\n",
    "        episode_rewards_Adv = 0\n",
    "        \n",
    "        # While the agents have not reached the terminal state\n",
    "        while not done:\n",
    "            # Agents choose actions \n",
    "            # * Note: They choose the actions simultaneously\n",
    "            a1 = P1.act(obs=s, env=None)\n",
    "            a2 = P2.act(obs=s, env=None)\n",
    "            \n",
    "            # Save locations for logging before a step is made\n",
    "            DM_location_old = env.player_0_pos.copy()\n",
    "            Adv_location_old = env.player_1_pos.copy()\n",
    "            \n",
    "            # Transition to next time step\n",
    "            s_new, rewards, done =  env.step((a1,a2))\n",
    "\n",
    "            # Agents update their Q/Value functions\n",
    "            # * Note: They update their Q/Value functions simultaneously\n",
    "            P1.update(s, (a1, a2), s_new, (rewards[0], rewards[1]))\n",
    "            P2.update(s, (a2, a1), s_new, (rewards[1], rewards[0]))\n",
    "            \n",
    "            # Set the current state to the new state\n",
    "            s = s_new  \n",
    "            \n",
    "            # Add the observed reward to the episode reward of both agents \n",
    "            # * Note: The rewards are observed simultaneously\n",
    "            episode_rewards_DM += rewards[0]\n",
    "            episode_rewards_Adv += rewards[1]\n",
    "        \n",
    "            # Log state in single episode\n",
    "            trajectory_log_single_epoch.append({\n",
    "                'DM_location_old': DM_location_old,\n",
    "                'Adv_location_old': Adv_location_old,\n",
    "                'DM_location_new': env.player_0_pos.copy(),\n",
    "                'Adv_location_new': env.player_1_pos.copy(),\n",
    "                'coin1': env.coin_0_pos.copy() if env.coin0_available else None,\n",
    "                'coin2': env.coin_1_pos.copy() if env.coin1_available else None, \n",
    "                'action_DM': env.combined_actions[a1],\n",
    "                'action_Adv': env.combined_actions[a2],\n",
    "                'reward_DM': rewards[0],\n",
    "                'reward_Adv': rewards[1],\n",
    "                'experiment': n,\n",
    "                'epoch': i\n",
    "            })\n",
    "            \n",
    "        # Append the episode rewards to the list of rewards for this experiment\n",
    "        r0s.append(episode_rewards_DM)\n",
    "        # Append the episode rewards to the list of rewards for this experiment\n",
    "        r1s.append(episode_rewards_Adv)\n",
    "        \n",
    "        # Append the trajectory log for this epoch to experiment log \n",
    "        trajectory_logs_single_experiment.append(trajectory_log_single_epoch)\n",
    "        \n",
    "        # After an epoch apply decay to exploration parameter\n",
    "\n",
    "        P1.update_epsilon(linear_epsilon_decay_arr[i])\n",
    "        P2.update_epsilon(linear_epsilon_decay_arr[i])\n",
    "        \n",
    "            \n",
    "    # Append the trajectory logs of this experiment to the total logs\n",
    "    trajectory_logs_all_experiments.append(trajectory_logs_single_experiment)\n",
    "    \n",
    "    env.reset() # Reset the environment at the very end\n",
    "    \n",
    "    r0ss.append(r0s)\n",
    "    r1ss.append(r1s)\n",
    "\n",
    "\n",
    "plot(r0ss, r1ss, moving_average_window_size=moving_average_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15eca0f56f3a45b9a5fb003fb00ce0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Experiments:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4abd05de7fc408190a5761c47739810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Initializing value function.:   0%|          | 0/38416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0829ee7e3d4e11ac8a619c7e92e608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pre-computing lookups for Level-1 DP Agent (Player DM):   0%|          | 0/38416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d54447a7ab74c2a9359b198086b7087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs (Exp 1):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4334117d3a8647548da0faa54340c618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Initializing value function.:   0%|          | 0/38416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee1b0213c00402ca05312199371b32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pre-computing lookups for Level-1 DP Agent (Player DM):   0%|          | 0/38416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2498eeef044450eb2230851bd389835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs (Exp 2):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333aa9b956994a7b8ec4cb80e1e08342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Initializing value function.:   0%|          | 0/38416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6d8eee537245c4abf2851e4805baba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pre-computing lookups for Level-1 DP Agent (Player DM):   0%|          | 0/38416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad5cbe09d5b4f079eb531a43b82c83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs (Exp 3):   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r0ss = []\n",
    "r1ss = []\n",
    "\n",
    "# Total trajectory logs for all experiments\n",
    "trajectory_logs_all_experiments = []\n",
    "\n",
    "# Run the experiments\n",
    "for n in tqdm(range(N_EXP), desc=\"Experiments\"):\n",
    "    \n",
    "    #np.random.seed(n)\n",
    "    \n",
    "    ## Initialize agents\n",
    "    P2 = IndQLearningAgentSoftmax(np.array(range(8)), n_states, learning_rate=learning_rate,\n",
    "                           epsilon=linear_epsilon_decay_arr[0], gamma=gamma, beta = 1)\n",
    "\n",
    "    # P2 = LevelKDPAgent_Stationary(\n",
    "    #     k=1, \n",
    "    #     action_space=np.array(range(len(env.combined_actions))),\n",
    "    #     opponent_action_space=np.array(range(len(env.combined_actions))),\n",
    "    #     n_states=n_states,\n",
    "    #     epsilon=linear_epsilon_decay_arr[0],\n",
    "    #     gamma=gamma,\n",
    "    #     player_id=1,\n",
    "    #     env=env\n",
    "    # ) \n",
    "\n",
    "    # P2 = ExpSmoother(env.available_actions_Adv, env.available_actions_Adv, learning_rate=0.7)\n",
    "    # P2 = RandomAgent( env.available_actions, p=0.5)\n",
    "    \n",
    "    \n",
    "    # P2 = LevelKDPAgent_Stationary(\n",
    "    #     k=2, \n",
    "    #     action_space=np.array(range(len(env.combined_actions))),\n",
    "    #     opponent_action_space=np.array(range(len(env.combined_actions))),\n",
    "    #     n_states=n_states,\n",
    "    #     epsilon=linear_epsilon_decay_arr[0],\n",
    "    #     gamma=gamma,\n",
    "    #     player_id=1,\n",
    "    #     env=env\n",
    "    # ) \n",
    "    \n",
    "    # P2 = ManhattanAgent(action_space=np.array(range(8)), coin_location = np.array([env.coin_0_pos, env.player_1_pos]), grid_size = grid_size, player_id = 1)\n",
    "\n",
    "    # P2 = LevelKDPAgent_Dynamic(\n",
    "    #     k=1, \n",
    "    #     action_space=np.array(range(len(env.combined_actions))),\n",
    "    #     opponent_action_space=np.array(range(len(env.combined_actions))),\n",
    "    #     n_states=n_states,\n",
    "    #     epsilon=linear_epsilon_decay_arr[0],\n",
    "    #     gamma=gamma,\n",
    "    #     player_id=1,\n",
    "    #     env=env\n",
    "    # ) \n",
    "\n",
    "    \n",
    "    # P1 = IndQLearningAgentSoftmax(np.array(range(8)), n_states, learning_rate=learning_rate,\n",
    "    #                        epsilon=linear_epsilon_decay_arr[0], gamma=gamma, opponent_action_space=None, beta = 1)\n",
    "\n",
    "    \n",
    "    P1 = LevelKDPAgent_Stationary(\n",
    "        k=1, \n",
    "        action_space=np.array(range(len(env.combined_actions))),\n",
    "        opponent_action_space=np.array(range(len(env.combined_actions))),\n",
    "        n_states=n_states,\n",
    "        epsilon=linear_epsilon_decay_arr[0],\n",
    "        gamma=gamma,\n",
    "        player_id=0,\n",
    "        env=env\n",
    "    ) \n",
    "    \n",
    "    # P1 = LevelKDPAgent_NonStationary(\n",
    "    #     k=2,\n",
    "    #     action_space=np.array(range(len(env.combined_actions))),\n",
    "    #     opponent_action_space=np.array(range(len(env.combined_actions))),\n",
    "    #     n_states=n_states,\n",
    "    #     epsilon=linear_epsilon_decay_arr[0],\n",
    "    #     gamma=gamma,\n",
    "    #     player_id=0,\n",
    "    #     env=env\n",
    "    # ) \n",
    "    \n",
    "    # P1 = LevelKDPAgent_Dynamic(\n",
    "    #     k=2, \n",
    "    #     action_space=np.array(range(len(env.combined_actions))),\n",
    "    #     opponent_action_space=np.array(range(len(env.combined_actions))),\n",
    "    #     n_states=n_states,\n",
    "    #     epsilon=linear_epsilon_decay_arr[0],\n",
    "    #     gamma=gamma,\n",
    "    #     player_id=0,\n",
    "    #     env=env\n",
    "    # ) \n",
    "    \n",
    "    # P1 = DPAgent_PerfectModel(\n",
    "    #      action_space = np.array(range(len(env.combined_actions))),\n",
    "    #      opponent_action_space = np.array(range(len(env.combined_actions))),\n",
    "    #      n_states=n_states,\n",
    "    #      gamma=gamma,\n",
    "    #      player_id=0,\n",
    "    #      env=env,\n",
    "    #      enemy=P2\n",
    "    # ) \n",
    "    \n",
    "    # P1 = ManhattanAgent(action_space=np.array(range(8)), coin_location = np.array([env.coin_0_pos, env.player_1_pos]), grid_size = grid_size, player_id = 0)\n",
    "\n",
    "\n",
    "    \n",
    "    # Reset the reward vectors for the experiment\n",
    "    r0s = []\n",
    "    r1s = []\n",
    "    \n",
    "    # Trajectory logs for visualization\n",
    "    trajectory_logs_single_experiment = []\n",
    "    \n",
    "    # Run through episodes\n",
    "    for i in tqdm(range(n_iter), desc=f\"Epochs (Exp {n+1})\"):\n",
    "\n",
    "        # Initialize the end of episode flag\n",
    "        done = False\n",
    "        # Reset the environment after each episode\n",
    "        env.reset()\n",
    "        # Get the initial state\n",
    "        s = env.get_state()\n",
    "        # Trajectory log for this episode\n",
    "        trajectory_log_single_epoch = []\n",
    "        \n",
    "        # Log the initial state immediately after env.reset()\n",
    "        trajectory_log_single_epoch.append({\n",
    "            'DM_location_old': [\"None\", \"None\"],\n",
    "            'Adv_location_old': [\"None\", \"None\"],\n",
    "            'DM_location_new': env.player_0_pos.copy(),\n",
    "            'Adv_location_new': env.player_1_pos.copy(),\n",
    "            'coin1': env.coin_0_pos.copy() if env.coin0_available else None,\n",
    "            'coin2': env.coin_1_pos.copy() if env.coin1_available else None, \n",
    "            'action_DM': [\"None\", \"None\"],\n",
    "            'action_Adv': [\"None\", \"None\"],\n",
    "            'reward_DM': None,\n",
    "            'reward_Adv': None,\n",
    "            'state': s, \n",
    "            'experiment': n,\n",
    "            'epoch': i\n",
    "        })\n",
    "\n",
    "        # Initialize cummulative observed rewards for this episode\n",
    "        episode_rewards_DM = 0\n",
    "        episode_rewards_Adv = 0\n",
    "        s_new = env.get_state()\n",
    "        # While the agents have not reached the terminal state\n",
    "        while not done:\n",
    "            # Agents choose actions \n",
    "            # * Note: They choose the actions simultaneously\n",
    "            a1 = P1.act(obs=s, env=None)\n",
    "            a2 = P2.act(obs=s, env=None)\n",
    "            \n",
    "            # Save locations for logging before a step is made\n",
    "            DM_location_old = env.player_0_pos.copy()\n",
    "            Adv_location_old = env.player_1_pos.copy()\n",
    "            \n",
    "            # DP agent performs update before next state is evaluated\n",
    "\n",
    "        \n",
    "            # Transition to next time step\n",
    "            s_new, rewards, done =  env.step((a1,a2))\n",
    "\n",
    "\n",
    "            # Update the Q matrix of adversary\n",
    "            #P1.update(s, (a1, a2), rewards=(rewards[0], rewards[1]), new_obs=s_new)\n",
    "            P1.update(s, (a1, a2), new_obs=s_new, rewards = None)\n",
    "            #P2.update(s, (a1, a2), rewards=[rewards[0],rewards[1]], new_obs=s_new)\n",
    "            \n",
    "            P2.update(s, (a2, a1), s_new, (rewards[1], rewards[0]))\n",
    "            # P2.update(s, (a1, a2))\n",
    "\n",
    "            \n",
    "            # Set the current state to the new state\n",
    "            s = s_new  \n",
    "            \n",
    "            # Add the observed reward to the episode reward of both agents \n",
    "            # * Note: The rewards are observed simultaneously\n",
    "            episode_rewards_DM += rewards[0]\n",
    "            episode_rewards_Adv += rewards[1]\n",
    "        \n",
    "            # Log state in single episode\n",
    "            trajectory_log_single_epoch.append({\n",
    "                'DM_location_old': DM_location_old,\n",
    "                'Adv_location_old': Adv_location_old,\n",
    "                'DM_location_new': env.player_0_pos.copy(),\n",
    "                'Adv_location_new': env.player_1_pos.copy(),\n",
    "                'coin1': env.coin_0_pos.copy() if env.coin0_available else None,\n",
    "                'coin2': env.coin_1_pos.copy() if env.coin1_available else None, \n",
    "                'action_DM': env.combined_actions[a1],\n",
    "                'action_Adv': env.combined_actions[a2],\n",
    "                'reward_DM': rewards[0],\n",
    "                'reward_Adv': rewards[1],\n",
    "                'experiment': n,\n",
    "                'epoch': i\n",
    "            })\n",
    "            \n",
    "        # Append the episode rewards to the list of rewards for this experiment\n",
    "        r0s.append(episode_rewards_DM)\n",
    "        # Append the episode rewards to the list of rewards for this experiment\n",
    "        r1s.append(episode_rewards_Adv)\n",
    "        \n",
    "        # Append the trajectory log for this epoch to experiment log \n",
    "        trajectory_logs_single_experiment.append(trajectory_log_single_epoch)\n",
    "        \n",
    "        # After an epoch apply decay to exploration parameter\n",
    "        P1.update_epsilon(linear_epsilon_decay_arr[i])\n",
    "        P2.update_epsilon(linear_epsilon_decay_arr[i])\n",
    "        \n",
    "    # Append the trajectory logs of this experiment to the total logs\n",
    "    trajectory_logs_all_experiments.append(trajectory_logs_single_experiment)\n",
    "    \n",
    "    env.reset() # Reset the environment at the very end\n",
    "\n",
    "    r0ss.append(r0s)\n",
    "    r1ss.append(r1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent P1 successfully loaded from p1_agent.joblib\n",
      "Loaded agent is of type: <class 'agent_DP.DPAgent_PerfectModel'>\n",
      "Loaded agent's level k: 1\n"
     ]
    }
   ],
   "source": [
    "# # This is the filename we'll save the agent to\n",
    "# filename = 'p1_agent.joblib'\n",
    "\n",
    "# # joblib.dump saves the object to the file\n",
    "# joblib.dump(P1, filename)\n",
    "\n",
    "# print(f\"Agent P1 successfully saved to {filename}\")\n",
    "\n",
    "\n",
    "\n",
    "# filename = 'p1_agent.joblib'\n",
    "\n",
    "# # joblib.load reads the object from the file\n",
    "# P1 = joblib.load(filename)\n",
    "\n",
    "# print(f\"Agent P1 successfully loaded from {filename}\")\n",
    "# print(f\"Loaded agent is of type: {type(P1)}\")\n",
    "# print(f\"Loaded agent's level k: {P1.k}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(r0ss, r1ss, moving_average_window_size=1000, dir = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_num_to_display = 0\n",
    "epoch_idx_to_display = 9999\n",
    "\n",
    "animate_trajectory_from_log(trajectory_logs_all_experiments[experiment_num_to_display][epoch_idx_to_display][:len(trajectory_logs_all_experiments[experiment_num_to_display][epoch_idx_to_display])], grid_size=grid_size, fps=1, dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"trajectory.mp4?cache=1752239839.800608\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(url=\"trajectory.mp4?cache=\" + str(time.time()), embed=False)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "TMDP_DP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
