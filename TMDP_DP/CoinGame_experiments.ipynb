{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa22979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary functions\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import yaml\n",
    "from pprint import pprint  # For better printing of the config dictionary\n",
    "from IPython.display import Video, display\n",
    "\n",
    "%matplotlib widget\n",
    "# For interactive plots in .ipynb scripts\n",
    "\n",
    "# Directing log messages of level INFO and higher to the console.\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    stream=sys.stdout,  # Explicitly direct logs to standard output\n",
    "    force=True # Overude jupyter kernel logging settings\n",
    ")\n",
    "\n",
    "from experiment_runner import load_config, run_experiment\n",
    "from utils.plot_utils import animate_trajectory_from_log, plot_reward_per_episode_series, plot_result_ration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc40fb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration and run the experiment\n",
    "config_file_path = 'configs/config.yaml'\n",
    "\n",
    "results_path = run_experiment(config_file_path, log_trajectory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e322763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the Experiment Run to Analyze\n",
    "# ---------------------------------------------\n",
    "# TODO: The path can be set to the specific, timestamped experiment folder you want to analyze.\n",
    "\n",
    "# --- Select moving average window size and range for the player reward plots\n",
    "\n",
    "plot_moving_average_window_size = 1\n",
    "reward_time_series_x_axis_plot_range = [0,10000]\n",
    "\n",
    "episode_range_to_eval = [0,9999]\n",
    "game_result_ratio_x_axis_plot_range = [0,10000]\n",
    "\n",
    "\n",
    "# --- Select which trajectory to animate ---\n",
    "# The log is structured as: [experiment_run][episode][step]\n",
    "run_to_animate = -1      # The last experiment run\n",
    "episode_to_animate = 8876  # The last episode of that run\n",
    "\n",
    "#results_run_directory = results_path\n",
    "\n",
    "results_run_directory = '/Users/ruzejjur/Github/ARAMARL_TMDP_DP/TMDP_DP/results/LevelK_MDP_DP_Agent_Stationary_vs_LevelK_TMDP_DP_Agent_Stationary_2025-08-08_14-23-11'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f3e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the directory exists before proceeding\n",
    "if not os.path.isdir(results_run_directory):\n",
    "    raise FileNotFoundError(f\"The specified directory does not exist: {results_run_directory}\")\n",
    "\n",
    "logging.info(f\"Loading results from: {results_run_directory}\")\n",
    "# --- Load Configuration ---\n",
    "config_path = os.path.join(results_run_directory, 'config.yaml')\n",
    "try:\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    logging.info(\"Configuration file 'config.yaml' loaded successfully.\")\n",
    "    # Use pprint for a cleaner print of the configuration dictionary\n",
    "    logging.info(\"\\n--- Experiment Configuration ---\")\n",
    "    pprint(config)\n",
    "    logging.info(\"--------------------------------\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"Configuration file not found at: {config_path}\")\n",
    "    config = None\n",
    "\n",
    "# --- Load Reward Data ---\n",
    "\n",
    "# Loading full rewards data\n",
    "full_rewards_p1_path = os.path.join(results_run_directory, 'full_rewards_per_episode_p1.npy')\n",
    "full_rewards_p2_path = os.path.join(results_run_directory, 'full_rewards_per_episode_p2.npy')\n",
    "try:\n",
    "    # Use np.load to read the saved NumPy array files\n",
    "    full_rewards_p1 = np.load(full_rewards_p1_path)\n",
    "    full_rewards_p2 = np.load(full_rewards_p2_path)\n",
    "    logging.info(f\"\\n Full reward data loaded successfully. Shape: {full_rewards_p1.shape}\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(\"Full reward data (.npy files) not found in the directory.\")\n",
    "\n",
    "    full_rewards_p1, full_rewards_p2 = None, None\n",
    "    \n",
    "# Loading positive rewards data\n",
    "positive_rewards_p1_path = os.path.join(results_run_directory, 'positive_rewards_per_episode_p1.npy')\n",
    "positive_rewards_p2_path = os.path.join(results_run_directory, 'positive_rewards_per_episode_p2.npy')\n",
    "try:\n",
    "    # Use np.load to read the saved NumPy array files\n",
    "    positive_rewards_p1 = np.load(positive_rewards_p1_path)\n",
    "    positive_rewards_p2 = np.load(positive_rewards_p2_path)\n",
    "    logging.info(f\"\\n Positive reward data loaded successfully. Shape: {positive_rewards_p1.shape}\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(\"Positive reward data (.npy files) not found in the directory.\")\n",
    "\n",
    "    positive_rewards_p1, positive_rewards_p2 = None, None\n",
    "    \n",
    "# Loading negative rewards data\n",
    "negative_rewards_p1_path = os.path.join(results_run_directory, 'negative_rewards_per_episode_p1.npy')\n",
    "negative_rewards_p2_path = os.path.join(results_run_directory, 'negative_rewards_per_episode_p2.npy')\n",
    "try:\n",
    "    # Use np.load to read the saved NumPy array files\n",
    "    negative_rewards_p1 = np.load(negative_rewards_p1_path)\n",
    "    negative_rewards_p2 = np.load(negative_rewards_p2_path)\n",
    "    logging.info(f\"\\n Negative reward data loaded successfully. Shape: {negative_rewards_p1.shape}\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(\"Negative reward data (.npy files) not found in the directory.\")\n",
    "    \n",
    "    negative_rewards_p1, negative_rewards_p2 = None, None\n",
    "    \n",
    "# Loading only step rewards data\n",
    "only_step_rewards_p1_path = os.path.join(results_run_directory, 'only_step_rewards_per_episode_p1.npy')\n",
    "only_step_rewards_p2_path = os.path.join(results_run_directory, 'only_step_rewards_per_episode_p2.npy')\n",
    "try:\n",
    "    # Use np.load to read the saved NumPy array files\n",
    "    only_step_rewards_p1 = np.load(only_step_rewards_p1_path)\n",
    "    only_step_rewards_p2 = np.load(only_step_rewards_p2_path)\n",
    "    logging.info(f\"\\n Only step reward data loaded successfully. Shape: {only_step_rewards_p1.shape}\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(\"Only step reward data (.npy files) not found in the directory.\")\n",
    "    \n",
    "    only_step_rewards_p1, only_step_rewards_p2 = None, None\n",
    "    \n",
    "# Loading full rewards without coin data\n",
    "full_rewards_without_coin_p1_path = os.path.join(results_run_directory, 'full_rewards_without_coin_per_episode_p1.npy')\n",
    "full_rewards_without_coin_p2_path = os.path.join(results_run_directory, 'full_rewards_without_coin_per_episode_p2.npy')\n",
    "try:\n",
    "    # Use np.load to read the saved NumPy array files\n",
    "    full_rewards_without_coin_p1 = np.load(full_rewards_without_coin_p1_path)\n",
    "    full_rewards_without_coin_p2 = np.load(full_rewards_without_coin_p2_path)\n",
    "    logging.info(f\"\\n Full reward without coin data loaded successfully. Shape: {full_rewards_without_coin_p1.shape}\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(\"Full reward without coin data (.npy files) not found in the directory.\")\n",
    "\n",
    "    full_rewards_without_coin_p1, full_rewards_without_coin_p2 = None, None\n",
    "    \n",
    "# Loading full rewards without step data\n",
    "full_rewards_without_step_p1_path = os.path.join(results_run_directory, 'full_rewards_without_step_per_episode_p1.npy')\n",
    "full_rewards_without_step_p2_path = os.path.join(results_run_directory, 'full_rewards_without_step_per_episode_p2.npy')\n",
    "try:\n",
    "    # Use np.load to read the saved NumPy array files\n",
    "    full_rewards_without_step_p1 = np.load(full_rewards_without_step_p1_path)\n",
    "    full_rewards_without_step_p2 = np.load(full_rewards_without_step_p2_path)\n",
    "    logging.info(f\"\\n Full reward without step data loaded successfully. Shape: {full_rewards_without_step_p1.shape}\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(\"Full reward without step data (.npy files) not found in the directory.\")\n",
    "\n",
    "    full_rewards_without_step_p1, full_rewards_without_step_p2 = None, None\n",
    "    \n",
    "# Loading game result for player 1\n",
    "game_result_p1_path = os.path.join(results_run_directory, 'game_result_episode_p1.npy')\n",
    "try:\n",
    "    # Use np.load to read the saved NumPy array files\n",
    "    game_result_p1 = np.load(game_result_p1_path)\n",
    "    logging.info(f\"\\n Game result for player 1 data loaded successfully. Shape: {game_result_p1.shape}\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(\"Game result for player 1 data (.npy files) not found in the directory.\")\n",
    "\n",
    "    game_result_p1 = None\n",
    "    \n",
    "# --- Load Trajectory Data ---\n",
    "# This will only exist if log_trajectory=True was used for the run.\n",
    "trajectory_path = os.path.join(results_run_directory, 'trajectory_log.npy')\n",
    "try:\n",
    "    trajectory_logs_all_experiments = np.load(trajectory_path, allow_pickle=True)\n",
    "    logging.info(f\"\\n Trajectory log loaded successfully. Contains {len(trajectory_logs_all_experiments)} run(s).\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(\"\\n Trajectory log ('trajectory_log.npy') not found. Was log_trajectory=True set during the run?\")\n",
    "\n",
    "    trajectory_logs_all_experiments = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4599c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Display the Reward Plot ---\n",
    "# We can either regenerate the plot from the loaded data or simply display the image that was saved.\n",
    "# Displaying the image is faster and guarantees we see the original result.\n",
    "\n",
    "# Plotting full rewards (negative + positive)\n",
    "if full_rewards_p1 is not None and full_rewards_p2 is not None:\n",
    "    logging.info(\"\\n--- Creating full reward plot from saved player rewards ---\")\n",
    "    plot_title = 'Cumulative full rewards (positive + negative) per episode'\n",
    "    \n",
    "    plot_reward_per_episode_series(full_rewards_p1, full_rewards_p2,\n",
    "                                   plot_title, episode_series_x_axis_plot_range = reward_time_series_x_axis_plot_range, moving_average_window_size=plot_moving_average_window_size, dir=None)\n",
    "else:\n",
    "    logging.info(\"\\nSkipping full rewards plot display as rewards were not not loaded.\")\n",
    "\n",
    "# Plotting only positive rewards\n",
    "if positive_rewards_p1 is not None and positive_rewards_p2 is not None:\n",
    "    logging.info(\"\\n--- Creating positive reward plot from saved player rewards ---\")\n",
    "    plot_title = 'Cumulative positive rewards per episode'\n",
    "    \n",
    "    plot_reward_per_episode_series(positive_rewards_p1, positive_rewards_p2,\n",
    "                                   plot_title, episode_series_x_axis_plot_range = reward_time_series_x_axis_plot_range, moving_average_window_size=plot_moving_average_window_size, dir=None)\n",
    "else:\n",
    "    logging.info(\"\\nSkipping positive rewards plot display as rewards were not not loaded.\")\n",
    "\n",
    "# Plotting only negative rewards\n",
    "if negative_rewards_p1 is not None and negative_rewards_p2 is not None:\n",
    "    logging.info(\"\\n--- Creating negative reward plot from saved player rewards ---\")\n",
    "    plot_title = 'Cumulative negative rewards per episode'\n",
    "    \n",
    "    plot_reward_per_episode_series(negative_rewards_p1, negative_rewards_p2,\n",
    "                                   plot_title, episode_series_x_axis_plot_range = reward_time_series_x_axis_plot_range, moving_average_window_size=plot_moving_average_window_size, dir=None)\n",
    "else:\n",
    "    logging.info(\"\\nSkipping negative rewards plot display as rewards were not not loaded.\")\n",
    "    \n",
    "# Plotting only step rewards\n",
    "if only_step_rewards_p1 is not None and only_step_rewards_p2 is not None:\n",
    "    logging.info(\"\\n--- Creating only step reward plot from saved player rewards ---\")\n",
    "    plot_title = 'Cumulative only step rewards per episode'\n",
    "    \n",
    "    plot_reward_per_episode_series(only_step_rewards_p1, only_step_rewards_p2,\n",
    "                                   plot_title, episode_series_x_axis_plot_range = reward_time_series_x_axis_plot_range, moving_average_window_size=plot_moving_average_window_size, dir=None)\n",
    "else:\n",
    "    logging.info(\"\\nSkipping only step rewards plot display as rewards were not not loaded.\")\n",
    "    \n",
    "# Plotting full rewards without coin\n",
    "if full_rewards_without_coin_p1 is not None and full_rewards_without_coin_p2 is not None:\n",
    "    logging.info(\"\\n--- Creating full reward without coin plot from saved player rewards ---\")\n",
    "    plot_title = 'Cumulative full rewards without coin per episode'\n",
    "    \n",
    "    plot_reward_per_episode_series(full_rewards_without_coin_p1, full_rewards_without_coin_p2,\n",
    "                                   plot_title, episode_series_x_axis_plot_range = reward_time_series_x_axis_plot_range, moving_average_window_size=plot_moving_average_window_size, dir=None)\n",
    "else:\n",
    "    logging.info(\"\\nSkipping full rewards without coin plot display as rewards were not not loaded.\")\n",
    "    \n",
    "# Plotting full rewards without step\n",
    "if full_rewards_without_step_p1 is not None and full_rewards_without_step_p2 is not None:\n",
    "    logging.info(\"\\n--- Creating full reward without step plot from saved player rewards ---\")\n",
    "    plot_title = 'Cumulative full rewards without step per episode'\n",
    "    \n",
    "    plot_reward_per_episode_series(full_rewards_without_step_p1, full_rewards_without_step_p2,\n",
    "                                   plot_title, episode_series_x_axis_plot_range = reward_time_series_x_axis_plot_range, moving_average_window_size=plot_moving_average_window_size, dir=None)\n",
    "else:\n",
    "    logging.info(\"\\nSkipping full rewards without step plot display as rewards were not not loaded.\")\n",
    "    \n",
    "    \n",
    "# Plotting win ratio for player 1 without step\n",
    "if game_result_p1 is not None:\n",
    "    logging.info(\"\\n--- Creating win ratio plot for player 1 ---\")\n",
    "    plot_title = 'Win ratio without step per episode'\n",
    "    \n",
    "    plot_result_ration(game_result_p1, episode_range_to_eval, plot_title, result_type_to_plot=\"win\",\n",
    "        episode_series_x_axis_plot_range=game_result_ratio_x_axis_plot_range, \n",
    "        dir=None)\n",
    "else:\n",
    "    logging.info(\"\\nSkipping Win ratio plot display as game results were not not loaded.\")\n",
    "    \n",
    "# Plotting loss ratio for player 1 without step\n",
    "if game_result_p1 is not None:\n",
    "    logging.info(\"\\n--- Creating loss ratio plot for player 1 ---\")\n",
    "    plot_title = 'Loss ratio without step per episode'\n",
    "    \n",
    "    plot_result_ration(game_result_p1, episode_range_to_eval, plot_title, result_type_to_plot=\"loss\",\n",
    "        episode_series_x_axis_plot_range=game_result_ratio_x_axis_plot_range, \n",
    "        dir=None)\n",
    "else:\n",
    "    logging.info(\"\\nSkipping Loss ratio plot display as game results were not not loaded.\")\n",
    "    \n",
    "# Plotting draw ratio for player 1 without step\n",
    "if game_result_p1 is not None:\n",
    "    logging.info(\"\\n--- Creating draw ratio plot for player 1 ---\")\n",
    "    plot_title = 'Draw ratio without step per episode'\n",
    "    \n",
    "    plot_result_ration(game_result_p1, episode_range_to_eval, plot_title, result_type_to_plot=\"draw\",\n",
    "        episode_series_x_axis_plot_range=game_result_ratio_x_axis_plot_range, \n",
    "        dir=None)\n",
    "else:\n",
    "    logging.info(\"\\nSkipping draw ratio plot display as game results were not not loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7f8fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Animate a Specific Episode from the Trajectory Log ---\n",
    "if trajectory_logs_all_experiments is not None and config is not None:\n",
    "    logging.info(\"\\n--- Generating Animation from Trajectory Log ---\")\n",
    "    \n",
    "    try:\n",
    "        log_for_one_episode = trajectory_logs_all_experiments[run_to_animate][episode_to_animate]\n",
    "        \n",
    "        grid_size = config['environment_settings']['params']['grid_size']\n",
    "        \n",
    "        # Generate the animation from this specific episode's log\n",
    "        animate_trajectory_from_log(log_for_one_episode, grid_size=grid_size, fps=2)\n",
    "        logging.info(\"Animation saved as 'trajectory.mp4'\")\n",
    "        \n",
    "        # Display the generated video in the notebook\n",
    "        display(Video(url=\"trajectory.mp4?cache=\" + str(time.time()), embed=False))\n",
    "        \n",
    "    except (IndexError, TypeError):\n",
    "        IndexError(\"Could not extract the specified trajectory log. Check if the run/episode index is valid.\")\n",
    "\n",
    "else:\n",
    "    logging.info(\"\\nSkipping animation as trajectory data or config was not loaded.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TMDP_DP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
